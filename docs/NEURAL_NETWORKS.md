# ğŸ§  Sistema de MÃºltiplas Redes Neurais - Spectral

## ğŸ“‹ VisÃ£o Geral

O Spectral implementa um **sistema modular de mÃºltiplas redes neurais** que podem ser usadas **individualmente** ou **combinadas em ensemble** para maximizar a accuracy de classificaÃ§Ã£o de eventos anÃ´malos.

---

## ğŸ—ï¸ Arquitetura Modular

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SISTEMA DE ML                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Video Encoder  â”‚  â”‚  Audio Encoder  â”‚  â”‚   Sensor    â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚   Encoder   â”‚ â”‚
â”‚  â”‚ â€¢ EfficientNet  â”‚  â”‚ â€¢ CNN           â”‚  â”‚ â€¢ MLP       â”‚ â”‚
â”‚  â”‚ â€¢ ResNet        â”‚  â”‚ â€¢ ResNet        â”‚  â”‚ â€¢ ResNet    â”‚ â”‚
â”‚  â”‚ â€¢ MobileNet     â”‚  â”‚ â€¢ Transformer   â”‚  â”‚ â€¢ Attention â”‚ â”‚
â”‚  â”‚ â€¢ ConvNeXt      â”‚  â”‚                 â”‚  â”‚             â”‚ â”‚
â”‚  â”‚ â€¢ ViT           â”‚  â”‚                 â”‚  â”‚             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                    â”‚                   â”‚         â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                              â”‚                               â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                   â”‚  Fusion Classifier  â”‚                   â”‚
â”‚                   â”‚                     â”‚                   â”‚
â”‚                   â”‚ â€¢ Concat            â”‚                   â”‚
â”‚                   â”‚ â€¢ Attention         â”‚                   â”‚
â”‚                   â”‚ â€¢ Gated             â”‚                   â”‚
â”‚                   â”‚ â€¢ Bilinear          â”‚                   â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                              â”‚                               â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                   â”‚    ClassificaÃ§Ã£o    â”‚                   â”‚
â”‚                   â”‚    (4 classes)      â”‚                   â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    ENSEMBLE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Combina mÃºltiplos modelos completos:                       â”‚
â”‚                                                               â”‚
â”‚  â€¢ Voting (majoritÃ¡ria)                                     â”‚
â”‚  â€¢ Average (mÃ©dia de probabilidades)                         â”‚
â”‚  â€¢ Weighted (mÃ©dia ponderada)                               â”‚
â”‚  â€¢ Stacking (meta-learner)                                  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Modelos DisponÃ­veis

### 1. Video Encoder (6 variantes)

| Variante | Backbone | Params | Speed | Uso |
|----------|----------|--------|-------|-----|
| **EfficientNet-B0** | efficientnet_b0 | ~5M | âš¡âš¡âš¡ | PadrÃ£o, balanceado |
| **EfficientNet-B2** | efficientnet_b2 | ~9M | âš¡âš¡ | Melhor accuracy |
| **ResNet50** | resnet50 | ~25M | âš¡âš¡ | Robusto, clÃ¡ssico |
| **MobileNetV3** | mobilenetv3_large | ~5M | âš¡âš¡âš¡âš¡ | Ultra rÃ¡pido |
| **ConvNeXt** | convnext_tiny | ~28M | âš¡ | Estado da arte |
| **ViT** | vit_small_patch16 | ~22M | âš¡ | AtenÃ§Ã£o global |

**AgregaÃ§Ã£o Temporal**:
- `mean`: MÃ©dia simples (rÃ¡pido)
- `max`: MÃ¡ximo (detecta picos)
- `lstm`: LSTM 2 camadas (sequencial)
- `attention`: Multi-head attention (melhor)

### 2. Audio Encoder (4 variantes)

| Variante | Arquitetura | Embedding | Speed | Uso |
|----------|-------------|-----------|-------|-----|
| **CNN Small** | 4 Conv layers | 256 | âš¡âš¡âš¡ | RÃ¡pido |
| **CNN Large** | 4 Conv layers | 512 | âš¡âš¡ | Melhor features |
| **ResNet** | Residual blocks | 256 | âš¡âš¡ | Robusto |
| **Transformer** | Self-attention | 256 | âš¡ | DependÃªncias temporais |

**Processamento**:
- Mel-spectrogram (n_mels: 64-128)
- FFT size: 2048
- Hop length: 512
- Log-scale (dB)

### 3. Sensor Encoder (3 variantes)

| Variante | Arquitetura | Params | Uso |
|----------|-------------|--------|-----|
| **Simple MLP** | 2 hidden layers | ~20K | PadrÃ£o, rÃ¡pido |
| **Deep ResNet** | 4 residual blocks | ~80K | Dados complexos |
| **Attention** | Transformer | ~100K | InterdependÃªncias |

---

## ğŸ”€ Fusion Strategies

### 1. Concat (ConcatenaÃ§Ã£o)

```python
video_emb + audio_emb + sensor_emb â†’ MLP â†’ classes
```

**PrÃ³s**: Simples, rÃ¡pido
**Contras**: NÃ£o captura interaÃ§Ãµes

### 2. Attention (AtenÃ§Ã£o)

```python
MultiHeadAttention(video, audio, sensor) â†’ MLP â†’ classes
```

**PrÃ³s**: Captura relaÃ§Ãµes entre modalidades
**Contras**: Mais lento

### 3. Gated (Com gates)

```python
video * gate(video) + audio * gate(audio) + sensor * gate(sensor) â†’ MLP
```

**PrÃ³s**: Aprende importÃ¢ncia de cada modalidade
**Contras**: Pode overfittar

### 4. Bilinear

```python
video âŠ— audio + video âŠ— sensor + audio âŠ— sensor â†’ MLP
```

**PrÃ³s**: Captura interaÃ§Ãµes de 2Âª ordem
**Contras**: Muitos parÃ¢metros

---

## ğŸ­ Variantes PrÃ©-Configuradas

### FusionVariants

```python
from ml.models import FusionVariants

# 1. Lightweight: RÃ¡pido e eficiente
model = FusionVariants.lightweight(num_classes=4)
# - MobileNetV3 + CNN Small + Simple MLP
# - Fusion: Concat
# - Params: ~8M
# - Speed: ~50ms

# 2. Balanced: BalanÃ§o velocidade/accuracy
model = FusionVariants.balanced(num_classes=4)
# - EfficientNet-B0 + ResNet + Deep MLP
# - Fusion: Attention
# - Params: ~12M
# - Speed: ~100ms

# 3. Accurate: MÃ¡xima accuracy
model = FusionVariants.accurate(num_classes=4)
# - EfficientNet-B2 + Transformer + Attention
# - Fusion: Bilinear
# - Params: ~25M
# - Speed: ~200ms

# 4. Vision Focused: Foco em vÃ­deo
model = FusionVariants.vision_focused(num_classes=4)
# - ConvNeXt + CNN Small + Simple MLP
# - Fusion: Gated
# - Para detecÃ§Ã£o de forma humanoide

# 5. Audio Focused: Foco em Ã¡udio
model = FusionVariants.audio_focused(num_classes=4)
# - MobileNetV3 + CNN Large + Simple MLP
# - Fusion: Attention
# - Para anÃ¡lise EVP
```

---

## ğŸª Sistema de Ensemble

### MÃ©todos de CombinaÃ§Ã£o

#### 1. Voting (VotaÃ§Ã£o MajoritÃ¡ria)

```python
# Hard voting: cada modelo vota em uma classe
# Classe mais votada vence
ensemble = NeuralEnsemble(models, method='voting')
```

**Uso**: Modelos bem diferentes, confianÃ§a binÃ¡ria

#### 2. Average (MÃ©dia)

```python
# Soft voting: mÃ©dia das probabilidades
# P_ensemble = mean(P_model1, P_model2, ...)
ensemble = NeuralEnsemble(models, method='average')
```

**Uso**: Modelos similares, padrÃ£o recomendado

#### 3. Weighted (Ponderado)

```python
# MÃ©dia ponderada por pesos
weights = [0.3, 0.5, 0.2]  # modelo 2 tem mais peso
ensemble = NeuralEnsemble(models, method='weighted', weights=weights)
```

**Uso**: Alguns modelos sÃ£o melhores que outros

#### 4. Stacking (Meta-Learner)

```python
# MLP aprende a combinar prediÃ§Ãµes
ensemble = NeuralEnsemble(models, method='stacking')
```

**Uso**: MÃ¡xima performance, precisa treinar meta-learner

---

## ğŸ“Š Ensembles PrÃ©-Configurados

### EnsembleVariants

```python
from ml.ensemble import EnsembleVariants

# 1. Fast Ensemble (3 modelos)
ensemble = EnsembleVariants.fast_ensemble()
# - Lightweight + Balanced + Vision Focused
# - Method: Average
# - Speed: ~150ms
# - Accuracy: +3-5% vs single model

# 2. Accurate Ensemble (3 modelos)
ensemble = EnsembleVariants.accurate_ensemble()
# - Balanced + Accurate + Audio Focused
# - Method: Weighted [0.3, 0.5, 0.2]
# - Speed: ~300ms
# - Accuracy: +5-8% vs single model

# 3. Full Ensemble (5 modelos + meta-learner)
ensemble = EnsembleVariants.full_ensemble()
# - Todos os 5 modelos + Stacking
# - Method: Stacking
# - Speed: ~500ms
# - Accuracy: +8-12% vs single model

# 4. Specialized Ensemble (EVP/Humanoide)
ensemble = EnsembleVariants.specialized_ensemble()
# - Vision (20%) + Audio (50%) + Balanced (30%)
# - Method: Weighted
# - Otimizado para detecÃ§Ã£o EVP
```

---

## ğŸ’» Uso PrÃ¡tico

### Treinamento de Modelo Ãšnico

```python
import torch
from ml.models import FusionVariants

# Criar modelo
model = FusionVariants.balanced(num_classes=4)

# Dados de exemplo
video = torch.randn(batch_size, 150, 3, 224, 224)
audio = torch.randn(batch_size, 220500)
sensors = torch.randn(batch_size, 15)

# Forward
logits = model(video, audio, sensors)

# PrediÃ§Ã£o
predicted_class, confidence = model.predict(video, audio, sensors)

print(f"Classe: {predicted_class.item()}")
print(f"ConfianÃ§a: {confidence.item():.2%}")
```

### InferÃªncia com Ensemble

```python
from ml.ensemble import EnsembleVariants

# Criar ensemble
ensemble = EnsembleVariants.fast_ensemble()
ensemble.eval()

# PrediÃ§Ã£o com detalhes
with torch.no_grad():
    result = ensemble.predict(video, audio, sensors, return_details=True)

print(f"Classe: {result.predicted_class}")
print(f"ConfianÃ§a: {result.confidence:.2%}")
print(f"MÃ©todo: {result.voting_method}")

# PrediÃ§Ãµes individuais
for pred in result.individual_predictions:
    print(f"Modelo {pred['model_index']}: "
          f"classe={pred['predicted_class']}, "
          f"conf={pred['confidence']:.2%}")
```

### Ensemble Personalizado

```python
from ml.models import FusionVariants
from ml.ensemble import NeuralEnsemble

# Criar modelos especÃ­ficos
models = [
    FusionVariants.lightweight(),
    FusionVariants.balanced(),
    FusionVariants.audio_focused()
]

# Criar ensemble com pesos customizados
ensemble = NeuralEnsemble(
    models=models,
    method='weighted',
    weights=[0.2, 0.5, 0.3]  # Dar mais peso ao balanced
)

# Uso
result = ensemble.predict(video, audio, sensors)
```

---

## ğŸ“ˆ ComparaÃ§Ã£o de Performance

| ConfiguraÃ§Ã£o | Params | Speed | Accuracy* | Uso Recomendado |
|--------------|--------|-------|-----------|-----------------|
| **Lightweight** | 8M | 50ms | 75% | Tempo real, edge |
| **Balanced** | 12M | 100ms | 82% | PadrÃ£o |
| **Accurate** | 25M | 200ms | 88% | Offline, melhor accuracy |
| **Fast Ensemble** | 24M | 150ms | 85% | Tempo real + ensemble |
| **Accurate Ensemble** | 37M | 300ms | 90% | Batch processing |
| **Full Ensemble** | 70M | 500ms | 93% | MÃ¡xima performance |

\* Valores estimados, dependem do dataset

---

## ğŸ“ Quando Usar Cada Abordagem

### Modelo Ãšnico

**Use quando**:
- âœ… InferÃªncia em tempo real estrito (< 100ms)
- âœ… Hardware limitado (mobile, edge)
- âœ… Dataset pequeno (overfitting com ensemble)

**Recomendado**: `FusionVariants.balanced()`

### Ensemble Pequeno (2-3 modelos)

**Use quando**:
- âœ… Quer melhorar accuracy sem muito overhead
- âœ… Tem GPU decent (RTX 3060+)
- âœ… LatÃªncia aceitÃ¡vel (< 200ms)

**Recomendado**: `EnsembleVariants.fast_ensemble()`

### Ensemble Completo (5+ modelos)

**Use quando**:
- âœ… Accuracy Ã© crÃ­tica
- âœ… Processamento em batch (nÃ£o tempo real)
- âœ… Tem GPU poderosa (RTX 4090)

**Recomendado**: `EnsembleVariants.full_ensemble()`

---

## ğŸ”§ ConfiguraÃ§Ã£o para ProduÃ§Ã£o

### Config para RTX 4090

```python
# config/ml_settings.py

ML_CONFIG = {
    # ProduÃ§Ã£o: Accurate Ensemble
    'model_type': 'accurate_ensemble',
    'batch_size': 16,
    'use_fp16': True,  # Mixed precision
    'num_workers': 4,

    # Fallback: Se latÃªncia > 300ms, usar Fast Ensemble
    'fallback_model': 'fast_ensemble',
    'max_latency_ms': 300
}
```

### OtimizaÃ§Ãµes

```python
# 1. Mixed Precision (FP16)
model = model.half()  # 2x mais rÃ¡pido, metade da memÃ³ria

# 2. TorchScript (JIT)
model_scripted = torch.jit.script(model)

# 3. ONNX (para deploy em outras plataformas)
torch.onnx.export(model, (video, audio, sensors), "model.onnx")

# 4. TensorRT (NVIDIA otimizado)
# Converta ONNX para TensorRT para mÃ¡xima velocidade
```

---

## ğŸ“š ReferÃªncias

- [EfficientNet](https://arxiv.org/abs/1905.11946)
- [ResNet](https://arxiv.org/abs/1512.03385)
- [Vision Transformer](https://arxiv.org/abs/2010.11929)
- [Multimodal Fusion](https://arxiv.org/abs/2103.05561)
- [Ensemble Methods](https://arxiv.org/abs/1404.3230)

---

**Ãšltima AtualizaÃ§Ã£o**: 2025-01-17
**VersÃ£o**: 1.0.0
**Hardware Target**: NVIDIA RTX 4090
