# ğŸ‘» Spectral - Sistema de DetecÃ§Ã£o de Anomalias Ambientais

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![Kotlin](https://img.shields.io/badge/kotlin-1.9+-purple.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)

**Sistema avanÃ§ado de detecÃ§Ã£o de anomalias em tempo real utilizando fusÃ£o multi-sensorial, Edge AI e Deep Learning**

[DocumentaÃ§Ã£o](#-documentaÃ§Ã£o) â€¢
[Arquitetura](#-arquitetura) â€¢
[InstalaÃ§Ã£o](#-instalaÃ§Ã£o) â€¢
[Uso](#-uso) â€¢
[Roadmap](#-roadmap)

</div>

---

## ğŸ¯ VisÃ£o Geral

**Spectral** Ã© um sistema completo de detecÃ§Ã£o de anomalias ambientais que combina:

- ğŸ“± **Cliente Android** (OPPO Reno 11 F5) com coleta multi-sensorial em tempo real
- ğŸ–¥ï¸ **Servidor Backend** (Python + RTX 4090) para processamento e anÃ¡lise
- ğŸ§  **Pipeline de IA** para classificaÃ§Ã£o automÃ¡tica de eventos
- ğŸ¨ **Interface Gradio** para visualizaÃ§Ã£o e controle

### CaracterÃ­sticas Principais

- âœ… **Coleta Multi-Sensorial**: MagnetÃ´metro, Ã¡udio, vÃ­deo, acelerÃ´metro, giroscÃ³pio, Bluetooth, NFC
- âœ… **Edge AI**: Pose estimation em tempo real usando NPU do dispositivo
- âœ… **DetecÃ§Ã£o Correlacionada**: AnÃ¡lise multi-sensorial com janelas temporais
- âœ… **Armazenamento Estruturado**: Eventos salvos com vÃ­deo, Ã¡udio e metadados
- âœ… **Deep Learning**: Modelo de fusÃ£o multimodal (vÃ­deo + Ã¡udio + sensores)
- âœ… **Tempo Real**: LatÃªncia < 50ms, streaming a 10Hz

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cliente Androidâ”‚         â”‚  Servidor       â”‚         â”‚  Interface      â”‚
â”‚  (Kotlin/MVVM)  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (FastAPI)      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (Gradio)       â”‚
â”‚                 â”‚         â”‚                 â”‚         â”‚                 â”‚
â”‚  â€¢ Sensores     â”‚  WebSocket  â€¢ Anomaly      â”‚   HTTP  â”‚  â€¢ AR Mode      â”‚
â”‚  â€¢ Edge AI (NPU)â”‚  10Hz   â”‚   Detection     â”‚         â”‚  â€¢ Analytics    â”‚
â”‚  â€¢ Streaming    â”‚         â”‚  â€¢ Event Storageâ”‚         â”‚  â€¢ AI Lab       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â€¢ ML Pipeline  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **Cliente Android** (Kotlin)
   - Coleta de dados de mÃºltiplos sensores @ 100Hz
   - Pose estimation em tempo real (TensorFlow Lite)
   - TransmissÃ£o via WebSocket @ 10Hz
   - Streaming de vÃ­deo 2K (30 FPS)

2. **Servidor Backend** (Python)
   - RecepÃ§Ã£o e processamento assÃ­ncrono (FastAPI)
   - DetecÃ§Ã£o de anomalias magnÃ©ticas e sonoras
   - CorrelaÃ§Ã£o multi-sensorial
   - Armazenamento de eventos (InfluxDB + PostgreSQL)
   - Pipeline de treinamento de IA (PyTorch + RTX 4090)

3. **Interface Gradio** (Python)
   - VisualizaÃ§Ã£o em tempo real
   - AnÃ¡lise espectral de Ã¡udio
   - Campo vetorial magnÃ©tico 3D
   - Timeline de eventos
   - Controles de treinamento de IA

---

## ğŸ“š DocumentaÃ§Ã£o

DocumentaÃ§Ã£o tÃ©cnica completa disponÃ­vel em `/docs`:

| Documento | DescriÃ§Ã£o |
|-----------|-----------|
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Arquitetura geral do sistema |
| [CLIENT_SPEC.md](docs/CLIENT_SPEC.md) | EspecificaÃ§Ã£o do cliente Android |
| [SERVER_SPEC.md](docs/SERVER_SPEC.md) | EspecificaÃ§Ã£o do servidor backend |
| [API_PROTOCOL.md](docs/API_PROTOCOL.md) | Protocolos de comunicaÃ§Ã£o |
| [AI_ML_SPEC.md](docs/AI_ML_SPEC.md) | Pipeline de Machine Learning |

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

#### Hardware
- **Cliente**: OPPO Reno 11 F5 (ou similar com NPU)
- **Servidor**:
  - GPU: NVIDIA RTX 4090 (ou RTX 3090/4080)
  - CPU: 16+ cores
  - RAM: 64GB+
  - Storage: 2TB+ SSD NVMe

#### Software
- **Cliente**: Android 8.0+ (API 26+)
- **Servidor**:
  - Python 3.11+
  - CUDA 12.1+
  - Docker (opcional)

### Setup do Servidor

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/Spectral.git
cd Spectral/server

# Criar ambiente virtual
python3.11 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas configuraÃ§Ãµes

# Iniciar servidor
python main.py
```

### Setup do Cliente Android

```bash
cd client/android

# Build com Gradle
./gradlew assembleDebug

# Instalar no dispositivo
adb install -r app/build/outputs/apk/debug/app-debug.apk
```

### Docker (Opcional)

```bash
# Servidor
docker-compose up -d

# Verificar logs
docker-compose logs -f
```

---

## ğŸ“Š Uso

### 1. Iniciar Sistema

```bash
# Terminal 1: Servidor Backend
cd server
python main.py

# Terminal 2: Interface Gradio
cd interface
python gradio_app.py
```

### 2. Conectar Cliente Android

1. Abra o app Spectral no dispositivo
2. Configure IP do servidor (Settings)
3. Clique em "Connect"
4. Aguarde confirmaÃ§Ã£o de conexÃ£o

### 3. Monitorar Dados

Acesse a interface Gradio em:
```
http://localhost:7860
```

**Abas DisponÃ­veis**:
- **AR Mode**: Stream de vÃ­deo em tempo real
- **Campo Vetorial**: VisualizaÃ§Ã£o 3D do magnetÃ´metro
- **AnÃ¡lise Sonora**: Espectrograma e osciloscÃ³pio
- **Timeline**: HistÃ³rico de eventos detectados
- **AI Lab**: Controles de treinamento

### 4. Treinar Modelo de IA

```bash
cd server/ml
python training.py --config configs/train_config.yaml
```

Ou via interface Gradio:
1. Acesse aba "AI Lab"
2. Selecione dataset de treinamento
3. Ajuste hiperparÃ¢metros
4. Clique em "Start Training"

---

## ğŸ§ª Exemplos

### Enviar Pacote de Dados (Python)

```python
import asyncio
import json
from websockets import connect

async def send_sensor_data():
    async with connect('ws://localhost:8000/ws/device_01') as websocket:
        packet = {
            "timestamp": 1705501234567890000,
            "device_id": "device_01",
            "magnetometer": {
                "x": 0.123, "y": -0.456, "z": 0.789,
                "magnitude": 0.936
            },
            "audio_peak": 0.75,
            "humanoid_detected": False
        }
        await websocket.send(json.dumps(packet))
        response = await websocket.recv()
        print(f"Server: {response}")

asyncio.run(send_sensor_data())
```

### Query de Eventos (REST API)

```bash
# Listar eventos de hoje
curl -X GET "http://localhost:8000/api/v1/events?start_date=2025-01-17"

# Obter evento especÃ­fico
curl -X GET "http://localhost:8000/api/v1/events/event_20250117_143052"

# Download de vÃ­deo do evento
curl -X GET "http://localhost:8000/api/v1/events/event_20250117_143052/video" \
     --output event_video.mp4
```

---

## ğŸ”¬ Sensores Suportados

| Sensor | FrequÃªncia | PrecisÃ£o | Uso |
|--------|------------|----------|-----|
| **MagnetÃ´metro** | 100 Hz | Â±0.1 ÂµT | DetecÃ§Ã£o de anomalias magnÃ©ticas |
| **Microfone** | 44.1 kHz | 16-bit | AnÃ¡lise espectral (FFT, EVP) |
| **CÃ¢mera** | 30 FPS | 1920x1080 | Pose estimation, evidÃªncia visual |
| **AcelerÃ´metro** | 100 Hz | Â±0.01 m/sÂ² | FusÃ£o de sensores |
| **GiroscÃ³pio** | 100 Hz | Â±0.001 rad/s | OrientaÃ§Ã£o da cÃ¢mera |
| **Bluetooth** | 1 Hz | - | DetecÃ§Ã£o de dispositivos |
| **NFC** | On-demand | - | Tags NFC |

---

## ğŸ§  Modelo de IA

### Arquitetura

**FusÃ£o Multimodal** (VÃ­deo + Ãudio + Sensores)

```
Video (EfficientNet-B0) â”€â”
                          â”œâ”€â–º Fusion MLP â”€â–º Classifier
Audio (1D CNN) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    [1600â†’128]    [4 classes]
                          â”‚
Sensors (MLP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Classes de ClassificaÃ§Ã£o

1. **RuÃ­do_Ambiente**: RuÃ­do natural sem correlaÃ§Ã£o
2. **InterferÃªncia_EletrÃ´nica**: Dispositivos eletrÃ´nicos
3. **Anomalia_Correlacionada**: Evento de interesse
4. **Forma_Humanoide_Potencial**: DetecÃ§Ã£o + anomalia

### Performance

- **Accuracy**: > 85% (target)
- **Inference Time**: < 200ms
- **Model Size**: ~100 MB

---

## ğŸ“ˆ Roadmap

### Fase 1: MVP âœ… (4-6 semanas)
- [x] Cliente Android com coleta bÃ¡sica
- [x] Servidor com WebSocket
- [x] DetecÃ§Ã£o de anomalia magnÃ©tica
- [x] Interface Gradio
- [ ] DocumentaÃ§Ã£o completa

### Fase 2: Edge AI + AnÃ¡lise AvanÃ§ada ğŸ”„ (3-4 semanas)
- [ ] IntegraÃ§Ã£o TensorFlow Lite
- [ ] Pose estimation em tempo real
- [ ] AnÃ¡lise FFT de Ã¡udio
- [ ] CorrelaÃ§Ã£o multi-sensorial
- [ ] Database layer (InfluxDB + PostgreSQL)

### Fase 3: Machine Learning ğŸ”œ (4-6 semanas)
- [ ] Dataset preparation
- [ ] Modelo de fusÃ£o multimodal
- [ ] Training loop
- [ ] IntegraÃ§Ã£o W&B
- [ ] Deploy do modelo

### Fase 4: Recursos AvanÃ§ados ğŸ”® (Futuro)
- [ ] Sonar acÃºstico (Doppler)
- [ ] AnÃ¡lise EVP avanÃ§ada
- [ ] Multi-client collaboration
- [ ] Cloud deployment (AWS/GCP)

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ™ Agradecimentos

### Frameworks e Bibliotecas
- [PyTorch](https://pytorch.org/) - Deep Learning framework
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework moderno
- [Gradio](https://gradio.app/) - Interface de ML
- [Ktor](https://ktor.io/) - Kotlin networking
- [TensorFlow Lite](https://www.tensorflow.org/lite) - Edge AI

### Pesquisa
- [ASSAP](https://www.assap.ac.uk/) - Guia de anÃ¡lise EVP
- [Social Voice Project](https://thesocialvoiceproject.org/) - AnÃ¡lise forense de voz
- [Madgwick Filter](https://x-io.co.uk/) - FusÃ£o de sensores

---

## ğŸ“ Contato

**Projeto Spectral** - DetecÃ§Ã£o de Anomalias Ambientais

- GitHub: [@spectral-project](https://github.com/spectral-project)
- Email: contact@spectral-project.dev

---

<div align="center">

**Desenvolvido com IA e CiÃªncia**

*VersÃ£o 1.0.0 - Janeiro 2025*

</div>
